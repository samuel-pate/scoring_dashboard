{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n",
      "1.19.4\n",
      "0.11.0\n",
      "3.3.2\n",
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import model_selection, dummy, metrics\n",
    "import pickle\n",
    "\n",
    "print(pd.__version__) #1.1.3\n",
    "print(np.__version__) #1.19.4\n",
    "print(sns.__version__) #0.11.0\n",
    "print(matplotlib.__version__) # 3.3.2\n",
    "print(sklearn.__version__) # 0.23.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cc522f5ac2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcat_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/pickle_cat_features.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcat_features_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mBETA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = pd.read_csv(\"data/X_train_resampled.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train_resampled.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "\n",
    "cat_features = pickle.load(open(\"data/pickle_cat_features.pkl\", \"rb\"))\n",
    "cat_features_index = np.where(X_train.columns.isin(cat_features))\n",
    "\n",
    "BETA = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "X_test.drop(columns=\"SK_ID_CURR\", inplace=True)\n",
    "y_train.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "y_test.drop(columns=\"SK_ID_CURR\", inplace=True)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}\")\n",
    "print(f\"y_train : {y_train.shape}\")\n",
    "print(f\"y_test : {y_test.shape}\")\n",
    "\n",
    "def replace_name(name):\n",
    "    for c in [\"[\",\"]\",\",\",\"{\",\"}\",'\"',\":\",\" \"]:\n",
    "        if c in name :\n",
    "            name = name.replace(c,\"_\")\n",
    "    return name\n",
    "            \n",
    "features = list(map(replace_name, X_train.columns))\n",
    "X_train.columns = features\n",
    "X_test.columns = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etablissement d'une baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# dummy classifier \n",
    "dummy_classifier = dummy.DummyClassifier(strategy=\"stratified\", random_state=123)\n",
    "dummy_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performances\n",
    "y_pred = dummy_classifier.predict_proba(X_test)[:, 1]\n",
    "baseline = metrics.fbeta_score(y_test, y_pred, beta=BETA)\n",
    "print(f\"Baseline F_beta par dummy classifier  : {baseline}\")\n",
    "\n",
    "del dummy_classifier\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement d'un classifieur LightGBM sur le train set sur 5 folds (5 classifieurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrique F_beta\n",
    "\n",
    "def f_beta(y_true, probas_pred):\n",
    "    y_pred = np.vectorize(lambda x : 0 if x<0.5 else 1)(probas_pred)\n",
    "    score = metrics.fbeta_score(y_true, y_pred, beta=BETA)\n",
    "    return \"F_beta\", score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# modèle de cross validation pour entraînement par fold\n",
    "folds = model_selection.StratifiedKFold(n_splits= 5, shuffle=True, random_state=123)\n",
    "\n",
    "# création des dataframes pour stocker les résultats\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    train_x, train_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    valid_x, valid_y = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # paramètres déterminés par optimisation Bayésienne\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=37,\n",
    "        colsample_bytree=0.26424255740815,\n",
    "        subsample=0.9222047021355166,\n",
    "        max_depth=6,\n",
    "        reg_alpha=0.8495823622837118,\n",
    "        reg_lambda=0.7247308695357746,\n",
    "        min_split_gain=0.05365093112258974,\n",
    "        min_child_weight=28.91981182288273,\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "        random_state=123,\n",
    "        categorical_feature=list(cat_features_index[0]))\n",
    "    \n",
    "    \n",
    "    # entraînement de chaque fold\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "        eval_metric=f_beta, verbose= 200, early_stopping_rounds= 200)\n",
    "\n",
    "    # stockage des prédictions\n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds += clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "    \n",
    "    # stockage des features importances\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = X_train.columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    _, score, _ = f_beta(valid_y, oof_preds[valid_idx])\n",
    "    print('Fold %2d F_beta : %.6f' % (n_fold + 1, score))\n",
    "    del clf, train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des performances\n",
    "\n",
    "_, train_score, _ = f_beta(y_train, oof_preds)\n",
    "_, test_score, _ = f_beta(y_test, sub_preds)\n",
    "print(f\"F_beta sur train set  : {train_score}\")\n",
    "print(f\"F_beta sur test set : {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de l'importance des features\n",
    "\n",
    "cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\\\n",
    "                    .sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement d'un LGBM Classifier unique sur le train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un set de validation\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# modèle avec les mêmes paramètres\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=10000,        \n",
    "        learning_rate=0.02,\n",
    "        num_leaves=37,\n",
    "        colsample_bytree=0.26424255740815,\n",
    "        subsample=0.9222047021355166,\n",
    "        max_depth=6,\n",
    "        reg_alpha=0.8495823622837118,\n",
    "        reg_lambda=0.7247308695357746,\n",
    "        min_split_gain=0.05365093112258974,\n",
    "        min_child_weight=28.91981182288273,\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "        random_state=123,\n",
    "        categorical_feature=list(cat_features_index[0]))\n",
    "\n",
    "# entraînement\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "    eval_metric=f_beta, verbose= 200, early_stopping_rounds= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performances\n",
    "\n",
    "y_pred = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:, 1]\n",
    "f_beta(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features importances\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df[\"feature\"] = X_train.columns\n",
    "feature_importance_df[\"importance\"] = clf.feature_importances_\n",
    "best_features_idx = feature_importance_df.sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.iloc[best_features_idx].sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances sont à peine moins bonnes, je garde donc ce principe d'un classifieur unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC du modèle\n",
    "\n",
    "print(metrics.roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recherche du seuil optimisant le f_beta\n",
    "\n",
    "scores = list()\n",
    "thresolds = np.linspace(0.1, 0.25, 16)\n",
    "\n",
    "for thres in np.linspace(0.1, 0.25, 16):\n",
    "    y_pred_label = [0 if i<=thres else 1 for i in y_pred]\n",
    "    score = metrics.fbeta_score(y_test, y_pred_label, beta=BETA)\n",
    "    scores.append(score)\n",
    "    print(f\"Seuil {thres} f-beta-score {score}\")\n",
    "    \n",
    "sns.lineplot(x=thresolds, y=scores)\n",
    "plt.title(\"F-beta-score en fonction du seuil de décision\")\n",
    "plt.xlabel(\"Seuil\")\n",
    "plt.ylabel(\"F-beta-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rapport de performances \n",
    "\n",
    "thres = 0.19\n",
    "y_pred_label = [0 if i<=thres else 1 for i in y_pred]\n",
    "print(metrics.classification_report(y_test, y_pred_label, digits=4))\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred_label)\n",
    "print(conf_matrix)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
